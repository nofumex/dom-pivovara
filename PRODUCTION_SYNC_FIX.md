# Исправление проблемы синхронизации больших файлов на продакшене

## Проблема
Большие файлы (более 400 товаров) не синхронизируются на продакшене, хотя маленькие файлы работают нормально. Локально большие файлы работают.

## Возможные причины

### 1. Лимиты размера запроса на уровне прокси/балансировщика

Если используется **nginx** или другой reverse proxy, нужно увеличить лимиты:

#### Для nginx:
```nginx
# В конфигурации nginx (обычно /etc/nginx/nginx.conf или /etc/nginx/sites-available/your-site)
http {
    client_max_body_size 50M;  # Увеличиваем лимит размера тела запроса
    client_body_timeout 300s;  # Увеличиваем таймаут для загрузки тела запроса
    proxy_read_timeout 1800s;  # 30 минут для чтения ответа от бэкенда
    proxy_connect_timeout 60s;
    proxy_send_timeout 1800s;
    
    # Для SSE (Server-Sent Events)
    proxy_buffering off;
    proxy_cache off;
    
    server {
        location /api/admin/sync-stock {
            proxy_pass http://your-backend;
            proxy_http_version 1.1;
            proxy_set_header Connection '';
            proxy_buffering off;
            proxy_cache off;
            chunked_transfer_encoding on;
        }
    }
}
```

После изменения конфигурации nginx:
```bash
sudo nginx -t  # Проверка конфигурации
sudo systemctl reload nginx  # Перезагрузка nginx
```

#### Для Cloudflare:
- В панели Cloudflare: **Rules** → **Page Rules**
- Добавьте правило для `/api/admin/sync-stock`:
  - **Cache Level**: Bypass
  - **Disable Performance**

#### Для Vercel:
Создайте файл `vercel.json` в корне проекта:
```json
{
  "functions": {
    "app/api/admin/sync-stock/route.ts": {
      "maxDuration": 1800
    }
  }
}
```

### 2. Лимиты памяти Node.js

Если на сервере недостаточно памяти, добавьте в переменные окружения или при запуске:

```bash
# Увеличиваем лимит памяти для Node.js
NODE_OPTIONS="--max-old-space-size=4096"  # 4GB
```

Или в `package.json`:
```json
{
  "scripts": {
    "start": "NODE_OPTIONS='--max-old-space-size=4096' next start"
  }
}
```

### 3. Проверка логов

После попытки синхронизации проверьте логи:

```bash
# Логи Next.js
pm2 logs  # Если используется PM2
# или
journalctl -u your-service -f  # Если используется systemd

# Логи nginx
sudo tail -f /var/log/nginx/error.log
sudo tail -f /var/log/nginx/access.log
```

Ищите ошибки:
- `413 Request Entity Too Large` - нужно увеличить `client_max_body_size` в nginx
- `504 Gateway Timeout` - нужно увеличить таймауты
- `502 Bad Gateway` - проблема с бэкендом (память, таймауты)
- `ECONNRESET` - разрыв соединения

### 4. Проверка размера файла

В коде добавлено логирование размера файла. Проверьте в логах:
```
[SYNC-STOCK] Начало синхронизации остатков из файла: filename.xlsx, размер: XX.XX MB
```

Если файл больше 50MB, это может быть проблемой.

### 5. Что было исправлено в коде

1. ✅ Увеличен `maxDuration` до 30 минут (1800 секунд)
2. ✅ Добавлена детальная обработка ошибок при чтении файла
3. ✅ Добавлен таймаут для чтения файла (5 минут)
4. ✅ Добавлено логирование размера файла и времени загрузки
5. ✅ Улучшены заголовки SSE для отключения буферизации
6. ✅ Добавлены заголовки для chunked encoding

### 6. Рекомендации

1. **Проверьте логи** после попытки синхронизации - там будет детальная информация об ошибке
2. **Увеличьте лимиты** на уровне прокси/балансировщика (см. выше)
3. **Увеличьте память** для Node.js процесса
4. **Рассмотрите разбиение** больших файлов на части (например, по 500-1000 товаров)

### 7. Диагностика

После применения исправлений, попробуйте синхронизировать файл и проверьте логи. Код теперь выводит:
- Размер файла
- Время загрузки файла в память
- Детальную информацию об ошибках (если они возникнут)

Если проблема сохраняется, пришлите:
1. Размер файла (из логов)
2. Точное сообщение об ошибке (из логов)
3. Конфигурацию nginx/proxy (если используется)
4. Информацию о сервере (память, CPU)

